{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras: 2.9.0\n",
      "pandas: 1.4.2\n",
      "numpy: 1.22.4\n",
      "sklearn: 1.1.1\n",
      "plotly: 5.9.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow / Keras\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Bidirectional, LSTM, RepeatVector, Dense, TimeDistributed # for creating layers inside the Neural Network\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "\n",
    "# Sklearn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "from sklearn.preprocessing import MinMaxScaler # for feature scaling\n",
    "\n",
    "# Visualization\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "print('plotly: %s' % plotly.__version__) # print version\n",
    "\n",
    "#file accessing\n",
    "import os\n",
    "# time stuff\n",
    "from datetime import timedelta\n",
    "import calendar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20141108.csv', '20141202.csv', '20141226.csv', '20150212.csv', '20150308.csv', '20150401.csv', '20150425.csv', '20150519.csv', '20150612.csv', '20150706.csv', '20150730.csv', '20150823.csv', '20150916.csv', '20151010.csv', '20151103.csv', '20151127.csv', '20151209.csv', '20151221.csv', '20160114.csv', '20160126.csv', '20160207.csv', '20160219.csv', '20160302.csv', '20160314.csv', '20160326.csv', '20160407.csv', '20160419.csv', '20160501.csv', '20160513.csv', '20160525.csv', '20160606.csv', '20160630.csv', '20160724.csv', '20160817.csv', '20160910.csv', '20160922.csv', '20161004.csv', '20161016.csv', '20161028.csv', '20161109.csv', '20161121.csv', '20161203.csv', '20161215.csv', '20161227.csv', '20170108.csv', '20170114.csv', '20170120.csv', '20170126.csv', '20170201.csv', '20170213.csv', '20170225.csv', '20170309.csv', '20170321.csv', '20170402.csv', '20170414.csv', '20170426.csv', '20170508.csv', '20170520.csv', '20170601.csv', '20170613.csv', '20170625.csv', '20170707.csv', '20170719.csv', '20170731.csv', '20170812.csv', '20170824.csv', '20170905.csv', '20170917.csv', '20170929.csv', '20171011.csv', '20171023.csv', '20171104.csv', '20171116.csv', '20171128.csv', '20171210.csv', '20171222.csv', '20180103.csv', '20180115.csv', '20180127.csv', '20180208.csv', '20180220.csv', '20180304.csv', '20180316.csv', '20180328.csv', '20180409.csv', '20180421.csv', '20180503.csv', '20180515.csv', '20180527.csv', '20180608.csv', '20180620.csv', '20180702.csv', '20180714.csv', '20180726.csv', '20180807.csv', '20180819.csv', '20180831.csv', '20180912.csv', '20180924.csv', '20181006.csv', '20181018.csv', '20181030.csv', '20181111.csv', '20181117.csv', '20181123.csv', '20181205.csv', '20181217.csv', '20181229.csv', '20190110.csv', '20190122.csv']\n"
     ]
    }
   ],
   "source": [
    "#get displacement for one dot over the whole time 60 20 20\n",
    "#open file by file\n",
    "CSVpath=\"InSAR_data_south/displacement/CSV/\"\n",
    "dir_list=[]\n",
    "lon_south=pd.read_csv('InSAR_data_south/longitude.csv')\n",
    "lat_south=pd.read_csv('InSAR_data_south/latitude.csv')\n",
    "for f in os.listdir(CSVpath):\n",
    "    name, ext=os.path.splitext(f)\n",
    "    if(ext=='.csv'):\n",
    "        dir_list.append(f)\n",
    "\n",
    "dir_list.sort()\n",
    "print(dir_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InSAR_data_south/displacement/CSV/20141108.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\DSFellowship\\LSTMAttempt710.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/DSFellowship/LSTMAttempt710.ipynb#ch0000002?line=11'>12</a>\u001b[0m df1\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mdf_temp\u001b[39m.\u001b[39miloc[:,\u001b[39m2\u001b[39m:\u001b[39m3\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/DSFellowship/LSTMAttempt710.ipynb#ch0000002?line=12'>13</a>\u001b[0m df1\u001b[39m=\u001b[39mdf_temp\u001b[39m.\u001b[39mset_index([df_temp\u001b[39m.\u001b[39mcolumns[\u001b[39m0\u001b[39m],df_temp\u001b[39m.\u001b[39mcolumns[\u001b[39m1\u001b[39m]])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/DSFellowship/LSTMAttempt710.ipynb#ch0000002?line=15'>16</a>\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([df,df1], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "for f in dir_list:\n",
    "    name, ext=os.path.splitext(f)\n",
    "    if(ext=='.csv'):\n",
    "        print(CSVpath+f)\n",
    "        df_temp=pd.read_csv(CSVpath+f)\n",
    "        df_temp.columns=lon_south.columns\n",
    "        df_temp.index=lat_south.columns[:-1]\n",
    "        df_temp=df_temp.unstack().reset_index()\n",
    "        df_temp.columns=['Longitude','Latitude',name]\n",
    "        #print(df1.head())\n",
    "        #put it onto the main'\n",
    "        df1=pd.DataFrame(data=df_temp.iloc[:,2:3])\n",
    "        df1=df_temp.set_index([df_temp.columns[0],df_temp.columns[1]])\n",
    "        \n",
    "        \n",
    "        df=pd.concat([df,df1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest=df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
